import os
import sys
import yaml
import schedule
import time
from datetime import datetime
from typing import List, Dict, Any
from loguru import logger

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°ç³»çµ±è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.crawler.google_news_crawler import GoogleNewsCrawler
from src.crawler.rss_crawler import RssCrawler
from src.crawler.finance_direct_crawler import FinanceNewsDirectCrawler
from src.summarizer.text_summarizer import TextSummarizer
from src.notification.line_notifier import LineNotifier
from src.crawler.utils import load_config, setup_logger

def run_crawler():
    """åŸ·è¡Œçˆ¬èŸ²ã€æ‘˜è¦å’Œé€šçŸ¥æµç¨‹ - å„ªåŒ–ç‰ˆæœ¬"""
    start_time = datetime.now()
    logger.info(f"ğŸš€ é–‹å§‹åŸ·è¡Œä¿éšªæ–°èçˆ¬èŸ²ä»»å‹™: {start_time}")
    
    try:
        # è¼‰å…¥é…ç½®
        config_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'config', 'config.yaml')
        config = load_config(config_path)
        
        # è¼¸å‡ºé…ç½®è³‡è¨Šç”¨æ–¼è¨ºæ–·
        logger.info(f"âœ… é…ç½®æª”æ¡ˆè¼‰å…¥æˆåŠŸ")
        logger.info(f"ğŸ“¡ å•Ÿç”¨çš„çˆ¬èŸ²ä¾†æº: {config['crawler'].get('sources', [])}")
        logger.info(f"ğŸ” æœå°‹é—œéµè©: {config['crawler'].get('search_terms', [])}")
        logger.info(f"â° æ™‚é–“é™åˆ¶: {config['crawler'].get('hours_limit', 24)} å°æ™‚")
        
        all_news = []
        
        # å„ªå…ˆä½¿ç”¨è²¡ç¶“æ–°èç›´æ¥çˆ¬èŸ²ï¼Œå› ç‚ºé€™æ›´æœ‰å¯èƒ½æ‰¾åˆ°ç›¸é—œæ–°è
        if 'finance_direct' in config['crawler']['sources']:
            logger.info("=== ğŸ¢ é–‹å§‹ä½¿ç”¨è²¡ç¶“æ–°èç›´æ¥çˆ¬èŸ² ===")
            try:
                finance_crawler = FinanceNewsDirectCrawler(config['crawler'])
                finance_news = finance_crawler.crawl()
                all_news.extend(finance_news)
                logger.info(f"ğŸ¢ è²¡ç¶“ç›´æ¥çˆ¬èŸ²çµæœ: {len(finance_news)} æ¢æ–°è")
                
                # è¼¸å‡ºè©³ç´°è³‡è¨Š
                for i, news in enumerate(finance_news[:5]):
                    logger.info(f"  ğŸ“° è²¡ç¶“æ–°è {i+1}: {news.title[:50]}... (ğŸ·ï¸ {news.keyword})")
                    
            except Exception as e:
                logger.error(f"âŒ è²¡ç¶“ç›´æ¥çˆ¬èŸ²åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        
        # ä½¿ç”¨Googleæ–°èçˆ¬èŸ²
        if 'google_news' in config['crawler']['sources']:
            logger.info("=== ğŸ” é–‹å§‹ä½¿ç”¨Googleæ–°èçˆ¬èŸ² ===")
            try:
                google_crawler = GoogleNewsCrawler(config['crawler'])
                google_news = google_crawler.crawl()
                all_news.extend(google_news)
                logger.info(f"ğŸ” Googleæ–°èçˆ¬èŸ²çµæœ: {len(google_news)} æ¢æ–°è")
                
                # è¼¸å‡ºè©³ç´°è³‡è¨Š
                for i, news in enumerate(google_news[:5]):
                    logger.info(f"  ğŸ“° Googleæ–°è {i+1}: {news.title[:50]}... (ğŸ·ï¸ {news.keyword})")
                    
            except Exception as e:
                logger.error(f"âŒ Googleæ–°èçˆ¬èŸ²åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        
        # ä½¿ç”¨RSSçˆ¬èŸ²
        if 'rss' in config['crawler']['sources']:
            logger.info("=== ğŸ“¡ é–‹å§‹ä½¿ç”¨RSSçˆ¬èŸ² ===")
            try:
                rss_crawler = RssCrawler(config['crawler'])
                rss_news = rss_crawler.crawl()
                all_news.extend(rss_news)
                logger.info(f"ğŸ“¡ RSSçˆ¬èŸ²çµæœ: {len(rss_news)} æ¢æ–°è")
                
                # è¼¸å‡ºè©³ç´°è³‡è¨Š
                for i, news in enumerate(rss_news[:5]):
                    logger.info(f"  ğŸ“° RSSæ–°è {i+1}: {news.title[:50]}... (ğŸ·ï¸ {news.keyword})")
                    
            except Exception as e:
                logger.error(f"âŒ RSSçˆ¬èŸ²åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        
        logger.info(f"ğŸ“Š === æ‰€æœ‰çˆ¬èŸ²å®Œæˆï¼Œç¸½å…±ç²å¾— {len(all_news)} æ¢æ–°è ===")
        
        # è©³ç´°è¼¸å‡ºå‰10æ¢æ–°èä¾›è¨ºæ–·
        if all_news:
            logger.info("ğŸ“‹ === å‰10æ¢æ–°èè©³ç´°åˆ—è¡¨ ===")
            for i, news in enumerate(all_news[:10]):
                logger.info(f"ğŸ“° æ–°è {i+1}:")
                logger.info(f"  ğŸ“‹ æ¨™é¡Œ: {news.title}")
                logger.info(f"  ğŸ¢ ä¾†æº: {news.source}")
                logger.info(f"  ğŸ·ï¸ é—œéµè©: {news.keyword}")
                logger.info(f"  ğŸ“… æ™‚é–“: {news.published_time}")
                logger.info(f"  ğŸ“„ å…§å®¹é•·åº¦: {len(news.content or '')} å­—å…ƒ")
                logger.info(f"  ğŸ‘€ å…§å®¹é è¦½: {(news.content or '')[:100]}...")
                logger.info("  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        
        # æ ¹æ“šé—œéµè©å„ªå…ˆæ’åºæ‰€æœ‰æ–°è
        if all_news:
            priority_map = {term: i for i, term in enumerate(config['crawler']['search_terms'])}
            all_news = sorted(all_news, key=lambda item: (
                priority_map.get(item.keyword, float('inf')),
                -item.published_time.timestamp()
            ))
            logger.info(f"ğŸ”„ æ–°èæŒ‰å„ªå…ˆç´šå’Œæ™‚é–“æ’åºå®Œæˆ")
        
        if not all_news:
            logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç›¸é—œæ–°èï¼")
            logger.info("ğŸ” å¯èƒ½çš„åŸå› ï¼š")
            logger.info("  1. é—œéµè©è¨­å®šéæ–¼åš´æ ¼")
            logger.info("  2. æ–°èä¾†æºç¶²ç«™çµæ§‹è®Šæ›´")
            logger.info("  3. ç¶²è·¯é€£ç·šå•é¡Œ")
            logger.info("  4. 24å°æ™‚å…§æ²’æœ‰ç›¸é—œä¿éšªæ–°è")
            logger.info("ğŸ’¡ å»ºè­°ï¼šæª¢æŸ¥é—œéµè©è¨­å®šæˆ–å¢åŠ æ™‚é–“ç¯„åœ")
            return
        
        # å–å‰15æ¢æœ€ç›¸é—œçš„æ–°è
        selected_news = all_news[:15]
        logger.info(f"ğŸ¯ é¸æ“‡å‰ {len(selected_news)} æ¢æœ€ç›¸é—œæ–°èé€²è¡Œæ‘˜è¦")
        
        # åˆå§‹åŒ–æ‘˜è¦å™¨
        logger.info("ğŸ“ === é–‹å§‹ç”Ÿæˆæ‘˜è¦ ===")
        try:
            summarizer = TextSummarizer(config['summarizer'])
            logger.info(f"âœ… æ‘˜è¦å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ æ‘˜è¦å™¨åˆå§‹åŒ–å¤±æ•—: {str(e)}")
            logger.info("ğŸ”„ ä½¿ç”¨å‚™ç”¨æ‘˜è¦æ–¹æ¡ˆ")
            summarizer = None
        
        # ç”Ÿæˆæ‘˜è¦
        news_summaries = []
        for i, item in enumerate(selected_news):
            logger.info(f"ğŸ“ æ­£åœ¨è™•ç†ç¬¬ {i+1}/{len(selected_news)} æ¢æ–°è: {item.title[:40]}...")
            
            try:
                if summarizer:
                    summary = summarizer.summarize(item.content)
                else:
                    # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å…§å®¹çš„å‰120å­—ä½œç‚ºæ‘˜è¦
                    content_preview = (item.content or "ç„¡å…§å®¹")
                    if len(content_preview) > 120:
                        summary = content_preview[:120] + "..."
                    else:
                        summary = content_preview
                
                news_summaries.append({
                    'title': item.title,
                    'summary': summary,
                    'url': item.url,
                    'source': item.source,
                    'keyword': item.keyword,
                    'published_time': item.published_time.strftime("%Y-%m-%d %H:%M")
                })
                
                logger.info(f"  âœ… æ‘˜è¦: {summary[:60]}...")
                
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆæ‘˜è¦æ™‚å‡ºéŒ¯: {str(e)}")
                # ä½¿ç”¨æ¨™é¡Œä½œç‚ºæ‘˜è¦
                news_summaries.append({
                    'title': item.title,
                    'summary': f"ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼Œè«‹æŸ¥çœ‹åŸæ–‡ã€‚",
                    'url': item.url,
                    'source': item.source,
                    'keyword': item.keyword,
                    'published_time': item.published_time.strftime("%Y-%m-%d %H:%M")
                })
        
        logger.info(f"ğŸ“ === æ‘˜è¦ç”Ÿæˆå®Œæˆï¼Œå…± {len(news_summaries)} æ¢ ===")
        
        # è¼¸å‡ºæ‘˜è¦ä¾›æª¢æŸ¥
        logger.info("ğŸ“‹ === æ‘˜è¦å…§å®¹é è¦½ ===")
        for i, summary_item in enumerate(news_summaries[:3]):
            logger.info(f"ğŸ“° æ‘˜è¦ {i+1}:")
            logger.info(f"  ğŸ“‹ {summary_item['title']}")
            logger.info(f"  ğŸ“ {summary_item['summary']}")
            logger.info(f"  ğŸ·ï¸ {summary_item['keyword']}")
            logger.info("  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        
        if len(news_summaries) > 3:
            logger.info(f"ğŸ“Š é‚„æœ‰ {len(news_summaries) - 3} æ¢æ‘˜è¦...")
        
        # åˆå§‹åŒ–Lineé€šçŸ¥
        logger.info("ğŸ“± === é–‹å§‹Lineé€šçŸ¥ ===")
        try:
            notifier = LineNotifier(config['line_notify'])
            
            # ç™¼é€æ‘˜è¦åˆ°Line
            sent = notifier.send_news_summary(news_summaries)
            if sent:
                logger.info(f"âœ… æˆåŠŸç™¼é€ {len(news_summaries)} æ¢æ–°èåˆ°Line")
            else:
                logger.error("âŒ ç™¼é€Lineé€šçŸ¥å¤±æ•—")
                
        except Exception as e:
            logger.error(f"âŒ Lineé€šçŸ¥åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
            logger.info("ğŸ“± è·³éLineé€šçŸ¥ï¼Œæ‘˜è¦å·²ç”Ÿæˆå®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œçˆ¬èŸ²ä»»å‹™æ™‚å‡ºéŒ¯: {str(e)}")
        import traceback
        logger.error(f"ğŸ” è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
    
    end_time = datetime.now()
    logger.info(f"ğŸ === çˆ¬èŸ²ä»»å‹™çµæŸï¼Œç¸½è€—æ™‚: {end_time - start_time} ===")

def main():
    """ä¸»å‡½æ•¸"""
    # è¨­ç½®è©³ç´°çš„æ—¥èªŒ
    setup_logger()
    
    # è¨­ç½®æ—¥èªŒç­‰ç´š
    logger.remove()
    logger.add(
        "insurance_crawler.log", 
        level="INFO", 
        rotation="1 day",
        retention="7 days",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
    )
    logger.add(
        sys.stdout, 
        level="INFO",
        format="<green>{time:HH:mm:ss}</green> | <level>{level}</level> | {message}"
    )
    
    if len(sys.argv) > 1 and sys.argv[1] == "--now":
        # ç«‹å³åŸ·è¡Œ
        logger.info("ğŸš€ === ç«‹å³åŸ·è¡Œä¿éšªæ–°èçˆ¬èŸ² ===")
        run_crawler()
    else:
        # æ’ç¨‹æ¯å¤©åŸ·è¡Œ
        logger.info("â° è¨­ç½®æ’ç¨‹ä»»å‹™...")
        # æ¯å¤©æ—©ä¸Š 8:00 åŸ·è¡Œçˆ¬èŸ²ä»»å‹™ (å°ç£æ™‚é–“)
        schedule.every().day.at("08:00").do(run_crawler)
        
        logger.info("ğŸ¤– çˆ¬èŸ²æœå‹™å·²å•Ÿå‹•ï¼Œç­‰å¾…æ’ç¨‹åŸ·è¡Œ...")
        logger.info("ğŸ“… åŸ·è¡Œæ™‚é–“ï¼šæ¯å¤©æ—©ä¸Š 8:00")
        logger.info("ğŸ’¡ æ‰‹å‹•åŸ·è¡Œè«‹ä½¿ç”¨ï¼špython main.py --now")
        
        while True:
            schedule.run_pending()
            time.sleep(60)

if __name__ == "__main__":
    main()
